{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis\n",
    "\n",
    "This notebook shows some simple examples of basic image analysis techniques.\n",
    "\n",
    "Although the code should be roughly self-explanatory, please read along with the slides 'Insight_Image_Analysis.pptx' in this respository for a better grasp of the concepts.\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Image analysis is an umbrella term for various methods and tools for manipulating and extracting information from images. There are fairly sophisticated algorithms like CNNs which would be difficult to cover in an introduction, but even these techniques build on some simple tools, such as segmentation and feature detection. I'll cover some of the basic tools in hopes that you'll be able to tackle more advanced techniques with the right vocabulary.\n",
    "\n",
    "\n",
    "# Topics\n",
    "\n",
    "- Structure of image data\n",
    "- Segmentation\n",
    "  - Thresholding\n",
    "  - Clustering\n",
    "  - Edges...\n",
    "- Feature detection\n",
    "  - Edge detection\n",
    "  - Structure detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Structure of Image Data\n",
    "\n",
    "If you don't have Pillow yet...\n",
    "\n",
    "    ! pip install --user Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open('Pavlovsk_bridge.png')\n",
    "img_array = np.asarray(img).copy()      # Convert image object to numpy array so we can inspect the data\n",
    "\n",
    "# PIL offers some basic image analysis tools, but I'll use numpy for the examples here\n",
    "# because you'll probably have to do most heavy lifting through numpy (and skimage or opencv) anyway\n",
    "\n",
    "print \"Height, width, and # of channels: \", img_array.shape\n",
    "\n",
    "plt.imshow(img_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are three channels for RGB in the above image.\n",
    "\n",
    "Most imaging packages default to encoding color via RGB (that's how almost all digital displays work so it makes sense).\n",
    "However, you could also encode by hue, saturation, and value. Or CMYK, or XYZ, or... you get the idea.\n",
    "All of these are just transforming the 3D RGB space to some other vector space.\n",
    "But other than being aware the other parametrizations exist, all you need to know is RGB.\n",
    "\n",
    "The other standard for images is a single channel for grayscale. We'll mostly work with grayscale below.\n",
    "\n",
    "A slightly less common standard is RGBA, which is the 3 usual RGB channels plus an alpha channel for the transparency of pixels. If you're working with pngs, icons, or gifs, you may run into these. If necessary, googling RGBA to RGB should show you a quick and dirty way of dealing with those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding by hand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = Image.open('Pavlovsk_bridge.png')\n",
    "\n",
    "\n",
    "# Below is how you'd do this with Pillow\n",
    "\n",
    "if False:\n",
    "    img.show()  # Warning: displays image by opening your OS's default image viewing software\n",
    "    img_gray = img.convert('L')     # Converts to grayscale using the Luma transform \n",
    "                                    # (we just want to segment on how \"bright\" the pixels are)\n",
    "                                    # https://en.wikipedia.org/wiki/Grayscale#Luma_coding_in_video_systems\n",
    "    img_thresh = img_gray.point(lambda x: 0 if x<128 else 255, '1')\n",
    "                                    # Segments image using threshold value of 128\n",
    "    img_thresh.show()\n",
    "    \n",
    "    \n",
    "# Now the numpy way\n",
    "\n",
    "img_arr = np.asarray(img).copy()\n",
    "plt.imshow(img_arr)\n",
    "plt.show()\n",
    "\n",
    "img_gray = np.mean( img_arr, 2)     # Convert to grayscale by taking the average of RGB values\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Pixel range is 0...255\n",
    "img_thresh = img_gray\n",
    "thresh_val = 128\n",
    "img_thresh[img_gray < thresh_val] = 0    # Black\n",
    "img_thresh[img_gray >= thresh_val] = 255 # White\n",
    "\n",
    "plt.imshow(img_thresh, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Adapted from https://stackoverflow.com/questions/18777873/convert-rgb-to-black-or-white\n",
    "# I stole the example image from wikipedia (https://en.wikipedia.org/wiki/Thresholding_(image_processing)). \n",
    "# It's kind of a bad example because the image already has high contrast but I'm running with it. Forgive me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's pick a threshold automatically... with Otsu Thresholding\n",
    "\n",
    "Otsu's method picks a threshold automatically by splitting pixels into two sets so that the relative variance between the sets is maximized. It is, in a way, a clustering algorithm for thresholding.\n",
    "\n",
    "There are also far more sophisticated algorithms for segmenting images through clustering. Just ask Scott!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you don't have skimage...\n",
    "\n",
    "    ! pip install --user scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, io\n",
    "from skimage import filters, color\n",
    "from skimage import exposure\n",
    "\n",
    "if True:\n",
    "    img = data.camera()               # scikit-image's example\n",
    "else:\n",
    "    img = io.imread('houses.jpg')     # wikipedia's example\n",
    "if False:\n",
    "    img = io.imread('Pavlovsk_bridge.png') \n",
    "    img = color.rgb2gray(img)         # That bridge again\n",
    "    \n",
    "val = filters.threshold_otsu(img)\n",
    "hist, bins_center = exposure.histogram(img)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(img > val, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.plot(bins_center, hist, lw=2)\n",
    "plt.axvline(val, color='k', ls='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostly ripped from http://www.scipy-lectures.org/packages/scikit-image/auto_examples/plot_threshold.html\n",
    "# See also https://en.wikipedia.org/wiki/Otsu%27s_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment via edges\n",
    "\n",
    "You can also find the edges in an image to define a boundary along which to segment the image... which brings us to..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detector\n",
    "\n",
    "OpenCV has built in functions for doing edge detection. Below you can see how Canny() finds points in the image with high gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Valve_original.PNG',0)\n",
    "edges = cv2.Canny(img,50,200)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively...\n",
    "\n",
    "Here's a custom-made Canny edge detector so you can see what's happening under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convolve(img1,img2):\n",
    "\n",
    "    # Convolve two 2D image numpy arrays\n",
    "    # img2 is considered the kernel, and we get the output after applying it as a filter on img1\n",
    "\n",
    "    # Get image info and initialize constants\n",
    "    kernelx = img2.shape[0]\n",
    "    kernely = img2.shape[1]\n",
    "    imagex = img1.shape[0]\n",
    "    imagey = img1.shape[1]\n",
    "\n",
    "    # Kernel must have odd dimensions\n",
    "    if (kernelx % 2 == 0) or (kernely % 2 == 0):\n",
    "        print('kernel must have odd dimensions')\n",
    "        return img1\n",
    "\n",
    "    output = img1*0.\n",
    "\n",
    "    # Convolve efficiently by adding the entire image (or a section of it) to itself\n",
    "    # and iterating for all necessary displacements (dx,dy)\n",
    "    for i in range(kernelx):\n",
    "        for j in range(kernely):\n",
    "            if (i < (kernelx*.5) ):\n",
    "                ia = int(kernelx*.5) - i\n",
    "                ib = imagex\n",
    "            else:\n",
    "                ia = 0\n",
    "                ib = imagex + int(kernelx*.5) - i\n",
    "            if (j < (kernely*.5) ):\n",
    "                ja = int(kernely*.5) - j\n",
    "                jb = imagey\n",
    "            else:\n",
    "                ja = 0\n",
    "                jb = imagey + int(kernely*.5) - j\n",
    "            dx = i - int(kernelx*.5)\n",
    "            dy = j - int(kernely*.5)\n",
    "            output[ia:ib,ja:jb] = output[ia:ib,ja:jb] + \\\n",
    "                img2[i,j] * img1[(ia+dx):(ib+dx),(ja+dy):(jb+dy)]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def canny(image):\n",
    "\n",
    "    # Canny edge detector https://en.wikipedia.org/wiki/Canny_edge_detector\n",
    "    # http://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html\n",
    "\n",
    "    Dx = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "    Dy = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
    "    Gx = convolve(image,Dx)\n",
    "    Gy = convolve(image,Dy)\n",
    "    G = np.sqrt(Gx**2 + Gy**2)\n",
    "    theta = np.arctan(Gy/(Gx+1e-20))\n",
    "\n",
    "    return [G,theta]\n",
    "\n",
    "\n",
    "def blur(image):\n",
    "\n",
    "    kernel = np.array([[1.,2,1],[2,4,2],[1,2,1]])/16.\n",
    "    output = convolve(image, kernel)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "img = Image.open('Valve_original.PNG')\n",
    "img = img.convert('L')\n",
    "img = np.asarray(img).copy()\n",
    "\n",
    "img = blur(img)\n",
    "edges,_ = canny(img)\n",
    "\n",
    "edges_thresh = edges > 110.\n",
    "\n",
    "plt.figure(figsize=(15,11))\n",
    "plt.subplot(221),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(222),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(224),plt.imshow(edges_thresh, cmap='gray', interpolation='nearest')\n",
    "plt.title('Thresholded Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical and horizontal features\n",
    "\n",
    "If you don't have opencv:\n",
    "\n",
    "    ! pip install --user opencv-python\n",
    "    \n",
    "Note - this is an unofficial wrapper for opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copied from openCV tutorial at \n",
    "https://docs.opencv.org/trunk/dd/dd7/tutorial_morph_lines_detection.html\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "def show_wait_destroy(winname, img):\n",
    "    if False:\n",
    "        cv2.imshow(winname, img)\n",
    "        cv2.moveWindow(winname, 500, 0)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(winname)\n",
    "    else:\n",
    "        plt.figure(figsize=(14,7))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "            \n",
    "def main(argv):\n",
    "    # [load_image]\n",
    "    # Check number of arguments\n",
    "    if len(argv) < 1:\n",
    "        print ('Not enough parameters')\n",
    "        print ('Usage:\\nmorph_lines_detection.py < path_to_image >')\n",
    "        return -1\n",
    "    # Load the image\n",
    "    src = cv2.imread(argv[0], cv2.IMREAD_COLOR)\n",
    "    # Check if image is loaded fine\n",
    "    if src is None:\n",
    "        print ('Error opening image: ' + argv[0])\n",
    "        return -1\n",
    "    # Show source image\n",
    "    cv2.imshow(\"src\", src)\n",
    "\n",
    "    \n",
    "    ''' Get grayscale image '''\n",
    "\n",
    "    # Transform source image to gray if it is not already\n",
    "    if len(src.shape) != 2:\n",
    "        gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = src\n",
    "    \n",
    "    show_wait_destroy(\"gray\", gray)\n",
    "\n",
    "    \n",
    "\n",
    "    ''' Segment it by thresholding at some value '''\n",
    "    \n",
    "    # Apply adaptiveThreshold at the bitwise_not of gray, notice the ~ symbol\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "    bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                cv2.THRESH_BINARY, 15, -2)    \n",
    "    show_wait_destroy(\"binary\", bw)\n",
    "\n",
    "\n",
    "    \n",
    "    ''' Prepare structure elements '''\n",
    "\n",
    "    # Create the images that will be used to extract the horizontal and vertical lines\n",
    "    # i.e. the structure elements for detecting horizontal and vertical features\n",
    "    horizontal = np.copy(bw)\n",
    "    vertical = np.copy(bw)\n",
    "    # Specify size on horizontal axis\n",
    "    cols = horizontal.shape[1]\n",
    "    horizontal_size = cols / 30\n",
    "    # Create structure element for extracting horizontal lines through morphology operations\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "\n",
    "    \n",
    "\n",
    "    ''' Extract horizontal lines '''\n",
    "\n",
    "    # Apply morphology operations\n",
    "    horizontal = cv2.erode(horizontal, horizontalStructure)\n",
    "    horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "  \n",
    "    show_wait_destroy(\"horizontal\", horizontal)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    ''' Extract vertical lines '''\n",
    "\n",
    "    # Specify size on vertical axis\n",
    "    rows = vertical.shape[0]\n",
    "    verticalsize = rows / 30\n",
    "    # Create structure element for extracting vertical lines through morphology operations\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalsize))\n",
    "    # Apply morphology operations\n",
    "    vertical = cv2.erode(vertical, verticalStructure)\n",
    "    vertical = cv2.dilate(vertical, verticalStructure)\n",
    "\n",
    "    # Show vertical lines\n",
    "    show_wait_destroy(\"vertical\", vertical)\n",
    "    # Inverse vertical image\n",
    "    vertical = cv2.bitwise_not(vertical)\n",
    "    show_wait_destroy(\"vertical_bit\", vertical)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Extract edges and smooth image according to the logic\n",
    "    1. extract edges\n",
    "    2. dilate(edges)\n",
    "    3. src.copyTo(smooth)\n",
    "    4. blur smooth img\n",
    "    5. smooth.copyTo(src, edges)\n",
    "    '''\n",
    "    # Step 1\n",
    "    edges = cv2.adaptiveThreshold(vertical, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                cv2.THRESH_BINARY, 3, -2)\n",
    "    show_wait_destroy(\"edges\", edges)\n",
    "    # Step 2\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel)\n",
    "    show_wait_destroy(\"dilate\", edges)\n",
    "    # Step 3\n",
    "    smooth = np.copy(vertical)\n",
    "    # Step 4\n",
    "    smooth = cv2.blur(smooth, (2, 2))\n",
    "    # Step 5\n",
    "    (rows, cols) = np.where(edges != 0)\n",
    "    vertical[rows, cols] = smooth[rows, cols]\n",
    "    # Show final result\n",
    "    show_wait_destroy(\"smooth - final\", vertical)\n",
    "    # [smooth]\n",
    "    return 0\n",
    "\n",
    "main(['src.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
